{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proiect Data Engineering\n",
    "_____\n",
    "\n",
    "### Echipa\n",
    "\n",
    "1. Benchia Madalin Codrin - 406 IS\n",
    "2. Coteanu Sebastian - 406 IS\n",
    "3. Coteanu Vlad - 406 IS\n",
    "4. Dimisca Cosmin - 406 IS\n",
    "5. Ghinea Alexandru Stefan - 407 IA\n",
    "6. Giosanu Andrei - 406 IS\n",
    "7. Nedelea Cosmin Daniel - 507 IA\n",
    "8. Petrescu Ana-Maria - 406 IS\n",
    "\n",
    "_____\n",
    "\n",
    "### Setul de date\n",
    "\n",
    "Setul de date folosit se poate gasi la adresa: https://www.kaggle.com/lava18/google-play-store-apps.\n",
    "Setul contine informatii legate de aplicatii Android hostate pe Google App Store si se imparte in doua\n",
    "fisiere CSV, unul cu informatii statistice ale aplicatiilor si unul cu cele mai relevante 100 comentarii\n",
    "lasate de utilizatori.\n",
    "\n",
    "_____\n",
    "\n",
    "### Descriere proiect\n",
    "\n",
    "Proiectul curent prelucreaza setul de date si foloseste trei modele, doua pentru clasificare si unul \n",
    "pentru regresie. 95% din date sunt folosite la antrenarea si testarea modelelor, iar 5% sunt pastrate\n",
    "pentru partea de Streaming. La finalul procesului de antrenare, unul dintre modele este salvat pentru\n",
    "a fi folosit, si el, in procesul de Streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT USED LIBRARIES\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from datetime import datetime\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "# Create an unique key used for file saving and create a Spark Context\n",
    "\n",
    "now = datetime.now()\n",
    "unique_key = now.strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "spark = SparkSession.builder.appName('google-play-store').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets from CSV files and analyze columns\n",
    "# Main file\n",
    "df = spark.read.csv('Data/googleplaystore.csv',inferSchema=True,header=True)\n",
    "df.printSchema()\n",
    "df.cache()\n",
    "\n",
    "# Reviews file\n",
    "df2 = spark.read.csv('Data/googleplaystore_user_reviews.csv',inferSchema=True,header=True)\n",
    "df2.printSchema()\n",
    "df2.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vom clasifica dupa feature-ul Installs si vom face o regresie dupa feature-ul Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe some data from both files\n",
    "df.show(5)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data from review file and add it to the main dataframe\n",
    "# Filter bad data\n",
    "df2 = df2.filter(df2[\"Sentiment\"] != \"nan\")\n",
    "\n",
    "# Merge Potential Score and Sentiment Polarity in a single column which should \n",
    "# be more influent when a review is closer to 0.5 subjectivity\n",
    "df2 = df2.withColumn(\"Potential Score\", (0.5 + 0.5 * df2[\"Sentiment_Polarity\"] * (1.5 - df2[\"Sentiment_Subjectivity\"])))\n",
    "df2 = df2.groupBy(\"App\").agg({\"Potential Score\" : \"avg\"}).withColumnRenamed(\"avg(Potential Score)\", \"avg score\")\n",
    "df = df.join(df2, df.App == df2.App).drop(\"App\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curatam datele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZE feature\n",
    "# Size data comes as: xK (KB), xM (MB)  or 'Varies with device'\n",
    "# If in xK format then it should be converted in MB\n",
    "# If in xM format then it should be parsed to x, default unit of measure should be M\n",
    "# If in Varies with device format then it should be parsed to the avg of their Category\n",
    "\n",
    "df_temp = df\n",
    "df_temp = df_temp.withColumn(\"Size uom\", F.expr(\"substring(Size, length(Size), 1)\"))\n",
    "\n",
    "df_temp = df_temp.withColumn(\"Size parsed\", F.when(df_temp[\"Size uom\"] == \"k\", \\\n",
    "    F.expr(\"substring(Size, 1, length(Size) - 1)\").cast('double') / 1024))\n",
    "\n",
    "df_temp = df_temp.withColumn(\"Size parsed\", F.when(df_temp[\"Size uom\"] == \"M\", \\\n",
    "    F.expr(\"substring(Size, 1, length(Size) - 1)\").cast('double')).otherwise(df_temp['Size parsed']))\n",
    "\n",
    "df_temp_avg_per_cat = df_temp.filter(df_temp[\"Size uom\"] != \"e\").groupBy(\"Category\").agg({\"Size parsed\" : \"avg\"}) \\\n",
    "                             .withColumnRenamed(\"avg(Size parsed)\", \"avg_size\") \\\n",
    "                             .withColumnRenamed(\"Category\", \"Category for avg\")\n",
    "\n",
    "df_temp = df_temp.join(df_temp_avg_per_cat, df_temp_avg_per_cat[\"Category for avg\"] == df_temp[\"Category\"])\n",
    "\n",
    "df_temp = df_temp.withColumn(\"Size parsed\", F.when(df_temp[\"Size uom\"] == \"e\", \\\n",
    "    df_temp[\"avg_size\"].cast('double')).otherwise(df_temp['Size parsed']))\n",
    "\n",
    "df_temp = df_temp.withColumn(\"Size parsed\", F.round(df_temp[\"Size parsed\"], 2))\n",
    "\n",
    "df = df_temp.drop(\"Size\", \"Size uom\", \"Category for avg\", \"avg_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price feature might have $ sign at the beggining for not null values\n",
    "\n",
    "df = df.withColumn(\"Price\", F.when(df[\"Price\"] != \"0\", F.expr(\"substring(Price, 2, length(Price) - 1)\").cast('double')) \\\n",
    "        .otherwise(df_temp['Price']).cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating feature - fill NaN ratings from Rating with 2.5 avg val\n",
    "\n",
    "df = df.withColumn(\"Rating\", F.when(df[\"Rating\"] == \"NaN\", F.lit(\"2.5\")).otherwise(df['Rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs cols which we want to classify by has many close values\n",
    "# So I will convert values over 10 to 10 and also add an upper roof of 100,000,000\n",
    "\n",
    "df = df.withColumn(\"Installs\", F.when(df[\"Installs\"] == \"0\", F.lit(\"10+\")).otherwise(df[\"Installs\"]))\n",
    "df = df.withColumn(\"Installs\", F.when(F.expr('substring(Installs, 1, length(Installs) - 1)').cast('double') < 100, F.lit(\"10+\")).otherwise(df[\"Installs\"]))\n",
    "df = df.withColumn(\"Installs\", F.when(F.expr('substring(Installs, 1, length(Installs) - 1)').cast('double') > 100000000, F.lit(\"100000000+\")).otherwise(df[\"Installs\"]))\n",
    "df = df.withColumn(\"Installs\", F.expr('substring(Installs, 1, length(Installs) - 1)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregatim datele pentru antrenare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAST used numeric features to double values\n",
    "\n",
    "features_to_cast_to_double = [ \\\n",
    "    'Rating', \\\n",
    "    'Reviews', \\\n",
    "    'Price', \\\n",
    "    'avg score'\n",
    "]\n",
    "for feature in features_to_cast_to_double:\n",
    "    print(\"Casting \" + feature + \" to double\")\n",
    "    df = df.withColumn(feature, df[feature].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEXING categorical features\n",
    "\n",
    "features_to_index = [\n",
    "    'Category', \\\n",
    "    'Type', \\\n",
    "    'Content Rating', \\\n",
    "    'Genres', \\\n",
    "    'Android Ver', \\\n",
    "    'Installs'\n",
    "]\n",
    "\n",
    "df_indexed = df\n",
    "df_indexed.cache()\n",
    "for feature in features_to_index:\n",
    "    print(\"Indexing: \" + feature)\n",
    "    indexer =  StringIndexer(inputCol=feature, outputCol=(feature + \" indexed\"))\n",
    "    df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n",
    "    df_indexed = df_indexed.drop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP unused columns\n",
    "\n",
    "featres_to_drop = [\n",
    "    'App', \\\n",
    "    'Last Updated', \\\n",
    "    'Current Ver',\n",
    "    'Android Ver indexed'\n",
    "]\n",
    "\n",
    "for feature in featres_to_drop:\n",
    "    print(\"Dropping: \" + feature)\n",
    "    df_indexed = df_indexed.drop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train test data and streaming data\n",
    "\n",
    "train_test_data, streaming_data = df_indexed.randomSplit([0.95, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Vectorizam datele si le clasificam folosind doi clasificatori\n",
    "1. Un RandomForestClassifier, pe care il vom si salva pentru a fi folosit mai tarziu\n",
    "2. Un MultilayerPerceptronClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizare\n",
    "\n",
    "feature_cols = train_test_data.columns\n",
    "feature_cols.remove('Installs indexed')\n",
    "\n",
    "assembler = VectorAssembler(inputCols = feature_cols, outputCol = \"features\", handleInvalid = \"error\")\n",
    "pipeline = Pipeline(stages=[assembler])\n",
    "outputModel = pipeline.fit(train_test_data)\n",
    "output = outputModel.transform(train_test_data)\n",
    "final_data = output.select(\"features\", \"Installs indexed\")\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"Installs indexed\", featuresCol=\"features\", numTrees=32, maxBins=120)\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Installs indexed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Random forest test Error = %g\" % (1.0 - accuracy))\n",
    "randomForestError = (1.0 - accuracy)\n",
    "\n",
    "# Save just the random forest model\n",
    "print(\"Saving the model\")\n",
    "strErr = str(round(randomForestError, 2))\n",
    "model.save(\"OutputGStore\\\\\" + str(unique_key) + \"-\" + strErr + \"-randomForestModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultilayerPerceptronClassifier\n",
    "\n",
    "layers = [len(feature_cols), 25, 10]\n",
    "trainer = MultilayerPerceptronClassifier(layers=layers, labelCol=\"Installs indexed\", featuresCol=\"features\", blockSize=500, seed=10003, maxIter=1000)\n",
    "model = trainer.fit(train_data)\n",
    "result = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Installs indexed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(result)\n",
    "print(\"Perceptron test Error = %g\" % (1.0 - accuracy))\n",
    "deepLearningError = (1.0 - accuracy)\n",
    "\n",
    "# Create a confussion matrix for evaluating the quality of prediction\n",
    "temp = result.select(\"Installs indexed\", \"prediction\")\n",
    "actual = [int(row['Installs indexed']) for row in temp.collect()]\n",
    "predicted = [int(row['prediction']) for row in temp.collect()]\n",
    "conf = confusion_matrix(actual, predicted)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Vectorizam datele si facem o regresie pe baza Rating-ului folosind un LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['avg score', 'Category indexed', 'Genres indexed', 'Installs indexed', \\\n",
    "     'Size parsed', 'Price', 'Type indexed', 'Reviews']\n",
    "\n",
    "assembler = VectorAssembler(inputCols = feature_cols, outputCol = \"features\", handleInvalid = \"error\")\n",
    "pipeline = Pipeline(stages=[assembler])\n",
    "outputModel = pipeline.fit(train_test_data)\n",
    "output = outputModel.transform(train_test_data)\n",
    "final_data = output.select(\"features\", \"Rating\")\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "lr = LinearRegression(featuresCol = \"features\", labelCol='Rating', regParam=0.1)\n",
    "lrModel = lr.fit(train_data)\n",
    "test_results = lrModel.evaluate(test_data)\n",
    "\n",
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))\n",
    "print(\"R2: {}\".format(test_results.r2))\n",
    "linearRegressionR2 = test_results.r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Analizam rezultatele si oprim contextul de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Script results: \")\n",
    "print(\"Random forest classifier error\", randomForestError)\n",
    "print(\"Neural networks classifier error\", deepLearningError)\n",
    "print(\"Linear regression R2\", linearRegressionR2)\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37432bit52aabb21ace84418a7082ac9074c32d9",
   "display_name": "Python 3.7.4 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}